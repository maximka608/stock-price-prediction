{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11651671,"sourceType":"datasetVersion","datasetId":7312115}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport random\nimport torch.nn as nn\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom gensim.models import KeyedVectors\nfrom nltk.stem.porter import PorterStemmer\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.optim  import AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:44:47.199229Z","iopub.execute_input":"2025-05-19T08:44:47.199576Z","iopub.status.idle":"2025-05-19T08:44:47.205490Z","shell.execute_reply.started":"2025-05-19T08:44:47.199555Z","shell.execute_reply":"2025-05-19T08:44:47.204689Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"nltk.download('punkt')\nstop_words = set(stopwords.words('english'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:52:11.208542Z","iopub.execute_input":"2025-05-19T04:52:11.209056Z","iopub.status.idle":"2025-05-19T04:52:11.525091Z","shell.execute_reply.started":"2025-05-19T04:52:11.209029Z","shell.execute_reply":"2025-05-19T04:52:11.524418Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model_path = \"/kaggle/input/wikinews300d1msubwordvec/wiki-news-300d-1M-subword.vec\"\nfasttext_model = KeyedVectors.load_word2vec_format(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:52:11.525828Z","iopub.execute_input":"2025-05-19T04:52:11.526161Z","iopub.status.idle":"2025-05-19T04:55:11.247478Z","shell.execute_reply.started":"2025-05-19T04:52:11.526141Z","shell.execute_reply":"2025-05-19T04:55:11.246899Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stocknews/Combined_News_DJIA.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:22.304826Z","iopub.execute_input":"2025-05-19T04:55:22.305435Z","iopub.status.idle":"2025-05-19T04:55:22.482602Z","shell.execute_reply.started":"2025-05-19T04:55:22.305409Z","shell.execute_reply":"2025-05-19T04:55:22.481954Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         Date  Label                                               Top1  \\\n0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n4  2008-08-14      1  b'All the experts admit that we should legalis...   \n\n                                                Top2  \\\n0            b'BREAKING: Musharraf to be impeached.'   \n1        b'Bush puts foot down on Georgian conflict'   \n2                 b\"Russia 'ends Georgia operation'\"   \n3  b\"When the president ordered to attack Tskhinv...   \n4  b'War in South Osetia - 89 pictures made by a ...   \n\n                                                Top3  \\\n0  b'Russia Today: Columns of troops roll into So...   \n1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n2  b'\"If we had no sexual harassment we would hav...   \n3  b' Israel clears troops who killed Reuters cam...   \n4  b'Swedish wrestler Ara Abrahamian throws away ...   \n\n                                                Top4  \\\n0  b'Russian tanks are moving towards the capital...   \n1  b'Georgian army flees in disarray as Russians ...   \n2  b\"Al-Qa'eda is losing support in Iraq because ...   \n3  b'Britain\\'s policy of being tough on drugs is...   \n4  b'Russia exaggerated the death toll in South O...   \n\n                                                Top5  \\\n0  b\"Afghan children raped with 'impunity,' U.N. ...   \n1      b\"Olympic opening ceremony fireworks 'faked'\"   \n2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n3  b'Body of 14 year old found in trunk; Latest (...   \n4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n\n                                                Top6  \\\n0  b'150 Russian tanks have entered South Ossetia...   \n1  b'What were the Mossad with fraudulent New Zea...   \n2  b'Why Microsoft and Intel tried to kill the XO...   \n3  b'China has moved 10 *million* quake survivors...   \n4  b\"Rushdie Condemns Random House's Refusal to P...   \n\n                                                Top7  \\\n0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n1  b'Russia angered by Israeli military sale to G...   \n2  b'Stratfor: The Russo-Georgian War and the Bal...   \n3  b\"Bush announces Operation Get All Up In Russi...   \n4  b'Poland and US agree to missle defense deal. ...   \n\n                                                Top8  ...  \\\n0  b\"The 'enemy combatent' trials are nothing but...  ...   \n1  b'An American citizen living in S.Ossetia blam...  ...   \n2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n3             b'Russian forces sink Georgian ships '  ...   \n4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n\n                                               Top16  \\\n0  b'Georgia Invades South Ossetia - if Russia ge...   \n1  b'Israel and the US behind the Georgian aggres...   \n2  b'U.S. troops still in Georgia (did you know t...   \n3                      b'Elephants extinct by 2020?'   \n4  b'Bank analyst forecast Georgian crisis 2 days...   \n\n                                               Top17  \\\n0                b'Al-Qaeda Faces Islamist Backlash'   \n1  b'\"Do not believe TV, neither Russian nor Geor...   \n2       b'Why Russias response to Georgia was right'   \n3  b'US humanitarian missions soon in Georgia - i...   \n4  b\"Georgia confict could set back Russia's US r...   \n\n                                               Top18  \\\n0  b'Condoleezza Rice: \"The US would not act to p...   \n1  b'Riots are still going on in Montreal (Canada...   \n2  b'Gorbachev accuses U.S. of making a \"serious ...   \n3             b\"Georgia's DDOS came from US sources\"   \n4  b'War in the Caucasus is as much the product o...   \n\n                                               Top19  \\\n0  b'This is a busy day:  The European Union has ...   \n1    b'China to overtake US as largest manufacturer'   \n2         b'Russia, Georgia, and NATO: Cold War Two'   \n3  b'Russian convoy heads into Georgia, violating...   \n4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n\n                                               Top20  \\\n0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n1                     b'War in South Ossetia [PICS]'   \n2  b'Remember that adorable 62-year-old who led y...   \n3  b'Israeli defence minister: US against strike ...   \n4  b'Georgian TV reporter shot by Russian sniper ...   \n\n                                               Top21  \\\n0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n1  b'Israeli Physicians Group Condemns State Tort...   \n2          b'War in Georgia: The Israeli connection'   \n3                     b'Gorbachev: We Had No Choice'   \n4  b'Saudi Arabia: Mother moves to block child ma...   \n\n                                               Top22  \\\n0  b'Caucasus in crisis: Georgia invades South Os...   \n1  b' Russia has just beaten the United States ov...   \n2  b'All signs point to the US encouraging Georgi...   \n3  b'Witness: Russian forces head towards Tbilisi...   \n4   b'Taliban wages war on humanitarian aid workers'   \n\n                                               Top23  \\\n0  b'Indian shoe manufactory  - And again in a se...   \n1  b'Perhaps *the* question about the Georgia - R...   \n2  b'Christopher King argues that the US and NATO...   \n3  b' Quarter of Russians blame U.S. for conflict...   \n4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n\n                                               Top24  \\\n0  b'Visitors Suffering from Mental Illnesses Ban...   \n1                 b'Russia is so much better at war'   \n2                        b'America: The New Mexico?'   \n3  b'Georgian president  says US military will ta...   \n4  b'Darfur rebels accuse Sudan of mounting major...   \n\n                                               Top25  \n0           b\"No Help for Mexico's Kidnapping Surge\"  \n1  b\"So this is what it's come to: trading sex fo...  \n2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n4  b'Philippines : Peace Advocate say Muslims nee...  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Label</th>\n      <th>Top1</th>\n      <th>Top2</th>\n      <th>Top3</th>\n      <th>Top4</th>\n      <th>Top5</th>\n      <th>Top6</th>\n      <th>Top7</th>\n      <th>Top8</th>\n      <th>...</th>\n      <th>Top16</th>\n      <th>Top17</th>\n      <th>Top18</th>\n      <th>Top19</th>\n      <th>Top20</th>\n      <th>Top21</th>\n      <th>Top22</th>\n      <th>Top23</th>\n      <th>Top24</th>\n      <th>Top25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-08-08</td>\n      <td>0</td>\n      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n      <td>b'BREAKING: Musharraf to be impeached.'</td>\n      <td>b'Russia Today: Columns of troops roll into So...</td>\n      <td>b'Russian tanks are moving towards the capital...</td>\n      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n      <td>b'150 Russian tanks have entered South Ossetia...</td>\n      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n      <td>...</td>\n      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n      <td>b'This is a busy day:  The European Union has ...</td>\n      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n      <td>b'Indian shoe manufactory  - And again in a se...</td>\n      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-08-11</td>\n      <td>1</td>\n      <td>b'Why wont America and Nato help us? If they w...</td>\n      <td>b'Bush puts foot down on Georgian conflict'</td>\n      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n      <td>b'Georgian army flees in disarray as Russians ...</td>\n      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n      <td>b'What were the Mossad with fraudulent New Zea...</td>\n      <td>b'Russia angered by Israeli military sale to G...</td>\n      <td>b'An American citizen living in S.Ossetia blam...</td>\n      <td>...</td>\n      <td>b'Israel and the US behind the Georgian aggres...</td>\n      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n      <td>b'Riots are still going on in Montreal (Canada...</td>\n      <td>b'China to overtake US as largest manufacturer'</td>\n      <td>b'War in South Ossetia [PICS]'</td>\n      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n      <td>b' Russia has just beaten the United States ov...</td>\n      <td>b'Perhaps *the* question about the Georgia - R...</td>\n      <td>b'Russia is so much better at war'</td>\n      <td>b\"So this is what it's come to: trading sex fo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-08-12</td>\n      <td>0</td>\n      <td>b'Remember that adorable 9-year-old who sang a...</td>\n      <td>b\"Russia 'ends Georgia operation'\"</td>\n      <td>b'\"If we had no sexual harassment we would hav...</td>\n      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n      <td>...</td>\n      <td>b'U.S. troops still in Georgia (did you know t...</td>\n      <td>b'Why Russias response to Georgia was right'</td>\n      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n      <td>b'Remember that adorable 62-year-old who led y...</td>\n      <td>b'War in Georgia: The Israeli connection'</td>\n      <td>b'All signs point to the US encouraging Georgi...</td>\n      <td>b'Christopher King argues that the US and NATO...</td>\n      <td>b'America: The New Mexico?'</td>\n      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-08-13</td>\n      <td>0</td>\n      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n      <td>b\"When the president ordered to attack Tskhinv...</td>\n      <td>b' Israel clears troops who killed Reuters cam...</td>\n      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n      <td>b'China has moved 10 *million* quake survivors...</td>\n      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n      <td>b'Russian forces sink Georgian ships '</td>\n      <td>...</td>\n      <td>b'Elephants extinct by 2020?'</td>\n      <td>b'US humanitarian missions soon in Georgia - i...</td>\n      <td>b\"Georgia's DDOS came from US sources\"</td>\n      <td>b'Russian convoy heads into Georgia, violating...</td>\n      <td>b'Israeli defence minister: US against strike ...</td>\n      <td>b'Gorbachev: We Had No Choice'</td>\n      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n      <td>b'Georgian president  says US military will ta...</td>\n      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-08-14</td>\n      <td>1</td>\n      <td>b'All the experts admit that we should legalis...</td>\n      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n      <td>b'Russia exaggerated the death toll in South O...</td>\n      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n      <td>b'Poland and US agree to missle defense deal. ...</td>\n      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n      <td>...</td>\n      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n      <td>b\"Georgia confict could set back Russia's US r...</td>\n      <td>b'War in the Caucasus is as much the product o...</td>\n      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n      <td>b'Taliban wages war on humanitarian aid workers'</td>\n      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def process_text(text, stemmer, stop_words):\n    if not isinstance(text, str):\n        return None\n    tokens = word_tokenize(text.lower())\n    # filtered_tokens = [t for t in tokens if t.isalpha() and t not in stop_words]  \n    stemmed_tokens = [stemmer.stem(t) for t in tokens]\n    return stemmed_tokens\n\ndef vectorize(tokens, fasttext_model, PAD_VECTOR, MAX_LEN):\n    vectors = []\n    mask = []\n    for t in tokens[:MAX_LEN]:\n        if t in fasttext_model:\n            vectors.append(fasttext_model[t])\n        else:\n            vectors.append(PAD_VECTOR)\n        mask.append(1) \n\n    while len(vectors) < MAX_LEN:\n        vectors.append(PAD_VECTOR)\n        mask.append(0) \n\n    return np.stack(vectors), np.array(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:25.215612Z","iopub.execute_input":"2025-05-19T04:55:25.216171Z","iopub.status.idle":"2025-05-19T04:55:25.221904Z","shell.execute_reply.started":"2025-05-19T04:55:25.216146Z","shell.execute_reply":"2025-05-19T04:55:25.221196Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def combine_embeddings(df, fasttext_model, num_news=1, MAX_LEN=32, EMBEDDING_DIM=300):\n    news, labels, masks = [], [], []\n\n    stop_words = set(stopwords.words('english'))\n    PAD_VECTOR = np.zeros(EMBEDDING_DIM)\n    num_news = 2 + num_news\n    stemmer = PorterStemmer()\n    \n    for _, row in df.iterrows():\n        day_news, day_mask = [], []\n        for idx in range(2, num_news):\n            text = row[idx]\n            tokens = process_text(text, stemmer, stop_words)\n        \n            if tokens is None or len(tokens) == 0:\n                continue\n        \n            embeddings, mask = vectorize(tokens, fasttext_model, PAD_VECTOR, MAX_LEN)\n            day_news.extend(embeddings) \n            day_mask.extend(mask)\n            \n        news.append(np.array(day_news))\n        labels.append(row[1])\n        masks.append(np.array(day_mask))\n    return (np.array(news), np.array(labels), np.array(masks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:27.952257Z","iopub.execute_input":"2025-05-19T04:55:27.952528Z","iopub.status.idle":"2025-05-19T04:55:27.958341Z","shell.execute_reply.started":"2025-05-19T04:55:27.952507Z","shell.execute_reply":"2025-05-19T04:55:27.957504Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def prepare_dataloaders(news, masks, labels, batch_size=64, test_size=0.1, val_size=0.1):\n    \n    encoder = LabelEncoder()\n    labels_encoded = encoder.fit_transform(labels)\n\n    X_train, X_test, y_train, y_test, masks_train, masks_test = train_test_split(\n        news, labels_encoded, masks, test_size=test_size, random_state=42)\n\n    X_train, X_val, y_train, y_val, masks_train, masks_val = train_test_split(\n        X_train, y_train, masks_train, test_size=val_size, random_state=42)\n\n    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n\n    def to_tensor(data, dtype):\n        return torch.tensor(data, dtype=dtype)\n\n    X_train_tensor = to_tensor(X_train, torch.float32)\n    y_train_tensor = to_tensor(y_train, torch.long)\n    masks_train_tensor = to_tensor(masks_train, torch.bool)\n\n    X_val_tensor = to_tensor(X_val, torch.float32)\n    y_val_tensor = to_tensor(y_val, torch.long)\n    masks_val_tensor = to_tensor(masks_val, torch.bool)\n\n    X_test_tensor = to_tensor(X_test, torch.float32)\n    y_test_tensor = to_tensor(y_test, torch.long)\n    masks_test_tensor = to_tensor(masks_test, torch.bool)\n\n    train_dataset = TensorDataset(X_train_tensor, masks_train_tensor, y_train_tensor)\n    val_dataset = TensorDataset(X_val_tensor, masks_val_tensor, y_val_tensor)\n    test_dataset = TensorDataset(X_test_tensor, masks_test_tensor, y_test_tensor)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=Tru)\n    return train_loader, val_loader, test_loader, class_weights_tensor, encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:19:12.574794Z","iopub.execute_input":"2025-05-19T07:19:12.575290Z","iopub.status.idle":"2025-05-19T07:19:12.582734Z","shell.execute_reply.started":"2025-05-19T07:19:12.575267Z","shell.execute_reply":"2025-05-19T07:19:12.582030Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def seed_everything(seed_value=0):\n    random.seed(seed_value)  \n    np.random.seed(seed_value)  \n    torch.manual_seed(seed_value) \n    torch.cuda.manual_seed(seed_value) \n    torch.cuda.manual_seed_all(seed_value) \n    torch.backends.cudnn.deterministic = True \n    torch.backends.cudnn.benchmark = False ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:31.704561Z","iopub.execute_input":"2025-05-19T04:55:31.705038Z","iopub.status.idle":"2025-05-19T04:55:31.709347Z","shell.execute_reply.started":"2025-05-19T04:55:31.705014Z","shell.execute_reply":"2025-05-19T04:55:31.708501Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, drop_prob, padding=1):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n        self.dropout = nn.Dropout(drop_prob)\n        self.batchnorm = nn.BatchNorm1d(out_channels)\n\n    def forward(self, x):\n        out = self.conv(x)\n        out = self.dropout(out)\n        out = self.batchnorm(out)\n        out = F.relu(out)\n        return out\n\n\nclass FractalBlock(nn.Module):\n    def __init__(self, n_columns, input_channels, output_channels, kernel_size, local_drop_prob, dropout_prob,\n                 global_drop_prob, training=True):\n        super().__init__()\n        self.n_columns = n_columns\n        self.columns = nn.ModuleList([nn.ModuleList() for _ in range(n_columns)])\n        self.max_depth = 2 ** (n_columns - 1)\n        self.dropout = nn.Dropout(dropout_prob)\n        self.local_drop_prob = local_drop_prob\n        self.global_drop_prob = global_drop_prob\n        self.count = np.zeros([self.max_depth], dtype=int)\n        dist = self.max_depth\n        for col in self.columns:\n            for i in range(self.max_depth):\n                if (i + 1) % dist == 0:\n                    first_block = (i + 1 == dist)\n                    if first_block:\n                        cur_input = input_channels\n                    else:\n                        cur_input = output_channels\n\n                    module = ConvBlock(cur_input, output_channels, kernel_size, dropout_prob)\n                    self.count[i] += 1\n                else:\n                    module = None\n                col.append(module)\n            dist //= 2\n\n    def drop_mask(self, B, global_cols, n_cols):\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        if isinstance(global_cols, np.ndarray):\n            global_cols = torch.tensor(global_cols, device=device)\n        \n        GB = global_cols.shape[0]\n        gdrop_cols = global_cols - (self.n_columns - n_cols)\n        gdrop_indices = torch.where(gdrop_cols >= 0)[0]\n        \n        gdrop_mask = torch.zeros(n_cols, GB, device=device, dtype=torch.float32)\n        if gdrop_indices.shape[0] > 0:\n            gdrop_mask[gdrop_cols[gdrop_indices], gdrop_indices] = 1.0\n            \n        LB = B - GB\n        prob_tensor = torch.ones(n_cols, LB, device=device) * (1. - self.local_drop_prob)\n        ldrop_mask = torch.bernoulli(prob_tensor)\n        alive_count = ldrop_mask.sum(dim=0)\n        \n        dead_indices = torch.where(alive_count == 0.)[0]\n        if dead_indices.shape[0] > 0:\n            random_rows = torch.randint(0, n_cols, (dead_indices.shape[0],), device=device)\n            ldrop_mask[random_rows, dead_indices] = 1.0\n        drop_mask = torch.cat((gdrop_mask, ldrop_mask), dim=1)\n        return drop_mask\n\n    def join(self, outs, global_cols):\n        n_cols = len(outs)\n        out = torch.stack(outs) \n\n        if self.training:\n            mask = self.drop_mask(out.size(1), global_cols, n_cols).to(out.device)  # [n_cols, B]\n            mask = mask.view(*mask.size(), 1, 1) \n            n_alive = mask.sum(dim=0)  \n            masked_out = out * mask  \n            n_alive[n_alive == 0.] = 1.\n            out = masked_out.sum(dim=0) / n_alive  \n        else:\n            out = out.mean(dim=0)\n        return out\n\n    def forward(self, x, global_cols):\n        outs = [x] * self.n_columns\n        for i in range(self.max_depth):\n            st = self.n_columns - self.count[i]\n            cur_outs = []\n\n            for c in range(st, self.n_columns):\n                cur_in = outs[c]\n                cur_module = self.columns[c][i]\n                if cur_module is not None:\n                    cur_outs.append(cur_module(cur_in))\n\n            joined = self.join(cur_outs, global_cols)\n\n            for c in range(st, self.n_columns):\n                outs[c] = joined\n\n        outs[-1] = self.dropout(outs[-1])\n        return outs[-1]\n\nclass FractalNet(nn.Module):\n    def __init__(self, n_blocks, n_columns, out_channels, kernel_size, local_drop_prob, drop_prob,\n                 global_drop_prob, embedding_dim):\n        super().__init__()\n        self.n_blocks = n_blocks\n        self.n_columns = n_columns\n        self.out_channels = out_channels\n        self.local_drop_prob = local_drop_prob\n        self.global_drop_prob = global_drop_prob\n\n        self.layers = nn.ModuleList()\n        total_layers = 0\n\n        current_channels = embedding_dim\n        for i in range(self.n_blocks):\n            print(f\"Block {i + 1}, Input channels: {current_channels}, Output channels: {out_channels[i]}\")\n            fractal_block = FractalBlock(n_columns, current_channels, out_channels[i], kernel_size,\n                                         local_drop_prob, drop_prob, global_drop_prob)\n            self.layers.append(fractal_block)\n            self.layers.append(nn.BatchNorm1d(out_channels[i]))\n            current_channels = out_channels[i]\n            total_layers += fractal_block.max_depth\n\n        self.initialize_weights()\n        print(f\"Total layers in network: {total_layers}\")\n\n    def initialize_weights(self):\n        for name, param in self.named_parameters():\n            if param.dim() > 1:\n                nn.init.xavier_uniform_(param)\n            else:\n                if 'bn.weight' in name:\n                    nn.init.ones_(param)\n                elif 'bn.bias' in name or 'bias' in name:\n                    nn.init.zeros_(param)\n\n    def forward(self, x):\n        B, T, E = x.shape             \n        x = x.permute(0, 2, 1)  \n\n        GB = int(x.size(0) * self.global_drop_prob)\n        global_cols = None\n\n        out = x\n        for layer in self.layers:\n            if isinstance(layer, FractalBlock):\n                global_cols = np.random.randint(0, self.n_columns, size=[GB])\n                out = layer(out, global_cols)  \n            else:\n                out = layer(out)              \n\n        out = out.permute(0, 2, 1)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:33.755264Z","iopub.execute_input":"2025-05-19T04:55:33.755982Z","iopub.status.idle":"2025-05-19T04:55:33.789040Z","shell.execute_reply.started":"2025-05-19T04:55:33.755957Z","shell.execute_reply":"2025-05-19T04:55:33.788182Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class NewsAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads=1, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads,\n                                          dropout=dropout, batch_first=True)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n    \n        key_padding_mask = ~mask\n        attn_output, attn_weights = self.attn(x, x, x, key_padding_mask=key_padding_mask)\n        out = self.norm(x + self.dropout(attn_output))\n        pooled = out.mean(dim=1)\n        return pooled, attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:38.176972Z","iopub.execute_input":"2025-05-19T04:55:38.177414Z","iopub.status.idle":"2025-05-19T04:55:38.182561Z","shell.execute_reply.started":"2025-05-19T04:55:38.177394Z","shell.execute_reply":"2025-05-19T04:55:38.181823Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, input_dim, hidden_dims=(1024, 512), dropout=0.3):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n        self.fc3 = nn.Linear(hidden_dims[1], 2)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x) \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:58:06.732474Z","iopub.execute_input":"2025-05-19T04:58:06.732992Z","iopub.status.idle":"2025-05-19T04:58:06.738783Z","shell.execute_reply.started":"2025-05-19T04:58:06.732970Z","shell.execute_reply":"2025-05-19T04:58:06.737806Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class NewsModel(nn.Module):\n    def __init__(self, embedding_dim, n_blocks, n_columns, out_channels, kernel_size, \n                 local_drop_prob, drop_prob, global_drop_prob, mlp_hidden_dims, dropout):\n        super().__init__()\n        \n        self.fractal_net = FractalNet(\n            n_blocks=n_blocks,\n            n_columns=n_columns,\n            out_channels=out_channels,\n            kernel_size=kernel_size,\n            local_drop_prob=local_drop_prob,\n            drop_prob=drop_prob,\n            global_drop_prob=global_drop_prob,\n            embedding_dim=embedding_dim\n        )\n        \n        fractal_output_dim = out_channels[-1]\n        \n        self.attention = NewsAttention(\n            embed_dim=fractal_output_dim,\n            num_heads=1, \n            dropout=dropout\n        )\n        \n        self.classifier = Classifier(\n            input_dim=fractal_output_dim,\n            hidden_dims=mlp_hidden_dims,\n            dropout=dropout\n        )\n        \n    def forward(self, x, mask):\n        fractal_output = self.fractal_net(x) \n        attention_output, attention_weights = self.attention(fractal_output, mask)\n        logits = self.classifier(attention_output)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:01:50.550983Z","iopub.execute_input":"2025-05-19T07:01:50.551765Z","iopub.status.idle":"2025-05-19T07:01:50.557310Z","shell.execute_reply.started":"2025-05-19T07:01:50.551733Z","shell.execute_reply":"2025-05-19T07:01:50.556492Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def train(model, train_loader, val_loader, num_epoch, optimizer, criterion, device):\n    best_f1 = 0.0\n    patience_counter = 0\n    best_model_state = None\n\n    for epoch in range(num_epoch):\n        model.train()\n        train_loss = 0.0\n        y_true_train = []\n        y_pred_train = []\n\n        for batch in train_loader:\n            tokens, masks, targets = batch\n            tokens = tokens.to(device)\n            masks = masks.to(device)\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(tokens, masks)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * tokens.size(0)\n\n            probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n            preds = probs.argmax(axis=1)\n\n            y_pred_train.extend(preds)\n            y_true_train.extend(targets.cpu().numpy())\n\n        avg_train_loss = train_loss / len(train_loader.dataset)\n        train_report = classification_report(y_true_train, y_pred_train, output_dict=True, zero_division=0)\n\n        model.eval()\n        val_loss = 0.0\n        y_true_val = []\n        y_pred_val = []\n\n        with torch.no_grad():\n            for batch in val_loader:\n                tokens, masks, targets = batch\n                tokens = tokens.to(device)\n                masks = masks.to(device)\n                targets = targets.to(device)\n\n                outputs = model(tokens, masks)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * tokens.size(0)\n\n                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n                preds = probs.argmax(axis=1)\n\n                y_pred_val.extend(preds)\n                y_true_val.extend(targets.cpu().numpy())\n\n        avg_val_loss = val_loss / len(val_loader.dataset)\n        val_report = classification_report(y_true_val, y_pred_val, output_dict=True, zero_division=0)\n        val_f1 = val_report['weighted avg']['f1-score']\n\n        if (epoch + 1) % 50 == 0 or epoch == 0:\n            print(f\"Epoch {epoch + 1}/{num_epoch}:\")\n            print(f\"  Train Precision: {train_report['weighted avg']['precision']:.4f}, \"\n                  f\"Recall: {train_report['weighted avg']['recall']:.4f}, \"\n                  f\"F1: {train_report['weighted avg']['f1-score']:.4f}\")\n            print(f\"  Val Precision: {val_report['weighted avg']['precision']:.4f}, \"\n                  f\"Recall: {val_report['weighted avg']['recall']:.4f}, \"\n                  f\"F1: {val_f1:.4f}\")\n\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n\n    return avg_train_loss, train_report, avg_val_loss, val_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:46.284515Z","iopub.execute_input":"2025-05-19T04:55:46.285333Z","iopub.status.idle":"2025-05-19T04:55:46.294519Z","shell.execute_reply.started":"2025-05-19T04:55:46.285303Z","shell.execute_reply":"2025-05-19T04:55:46.293784Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def test_model(model, test_dataloader, device, name):\n    model.eval()\n    y_true = []\n    y_pred = []\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            tokens, masks, targets = batch\n            tokens = tokens.to(device)\n            masks = masks.to(device)\n            targets = targets.to(device)\n\n            outputs = model(tokens, masks)\n            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n            preds = probs.argmax(axis=1)\n\n            y_true.extend(targets.cpu().numpy())\n            y_pred.extend(preds)\n\n    report = classification_report(y_true, y_pred, zero_division=0)\n    print(\"Classification Report:\\n\", report)\n\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(name, dpi=300, bbox_inches='tight')  \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:49.340478Z","iopub.execute_input":"2025-05-19T04:55:49.340956Z","iopub.status.idle":"2025-05-19T04:55:49.346552Z","shell.execute_reply.started":"2025-05-19T04:55:49.340926Z","shell.execute_reply":"2025-05-19T04:55:49.345912Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def validate(model, val_loader, criterion, device):\n    model.eval()\n    correct = 0\n    total = 0\n    running_loss = 0.0\n    \n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for tokens, masks, labels in val_loader:\n            tokens = tokens.to(device)\n            masks = masks.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(tokens, masks) \n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * tokens.size(0)\n\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    val_loss = running_loss / total\n    val_accuracy = correct / total\n    \n    report = classification_report(all_labels, all_preds, digits=4)\n    print(\"Classification Report:\\n\", report)\n    \n    return val_loss, val_accuracy, report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:51.435185Z","iopub.execute_input":"2025-05-19T04:55:51.435875Z","iopub.status.idle":"2025-05-19T04:55:51.441654Z","shell.execute_reply.started":"2025-05-19T04:55:51.435850Z","shell.execute_reply":"2025-05-19T04:55:51.440756Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"n_blocks_choices = [2, 3, 4]\nn_columns_choices = [2, 3, 4]\nbase_out_channels_choices = [\n    [16, 32, 64, 128],\n    [32, 64, 128, 256],\n    [64, 128, 256, 512]\n]\nlocal_drop_prob_choices = [0.0, 0.3, 0.5]\ndrop_prob_choices = [0.0, 0.1, 0.3, 0.4, 0.5]\nglobal_drop_prob_choices = [0.0, 0.1, 0.3, 0.4, 0.5]\ndropout_choices = [0.0, 0.1, 0.3]\nlr_choices = [1e-5, 1e-4, 1e-3]\n\ndef sample_params():\n    n_blocks = random.choice(n_blocks_choices)\n    n_columns = random.choice(n_columns_choices)\n    base_out_channels = random.choice(base_out_channels_choices)\n    out_channels = base_out_channels[:n_blocks]\n\n    return {\n        'n_blocks': n_blocks,\n        'n_columns': n_columns,\n        'out_channels': out_channels,\n        'local_drop_prob': random.choice(local_drop_prob_choices),\n        'drop_prob': random.choice(drop_prob_choices),\n        'global_drop_prob': random.choice(global_drop_prob_choices),\n        'dropout': random.choice(dropout_choices),\n        'lr': random.choice(lr_choices),\n        'kernel_size': 3,\n        'embedding_dim': 300\n    }\n\nbest_accuracy = 0\nbest_params = None\nnum_trials = 20\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nfor trial in range(num_trials):\n    params = sample_params()\n    print(f\"Trial {trial+1}/{num_trials}: {params}\")\n\n    model = NewsModel(\n        embedding_dim=params['embedding_dim'],\n        n_blocks=params['n_blocks'],\n        n_columns=params['n_columns'],\n        out_channels=params['out_channels'],\n        kernel_size=params['kernel_size'],\n        local_drop_prob=params['local_drop_prob'],\n        drop_prob=params['drop_prob'],\n        global_drop_prob=params['global_drop_prob'],\n        mlp_hidden_dims=[128, 128],\n        dropout=params['dropout'],\n    ).to(device)\n\n    news, labels, masks = combine_embeddings(df, fasttext_model, 3, 64)\n    train_loader, val_loader, test_loader, class_weights, encoder = prepare_dataloaders(news, masks, labels)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'])\n    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n\n    train(model, train_loader, val_loader, num_epoch=100, optimizer=optimizer,\n          criterion=criterion, device=device) \n\n    val_loss, val_accuracy, report = validate(model, val_loader, criterion, device)\n\n    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_params = params\n\nprint(f\"\\nBest accuracy: {best_accuracy:.4f}\")\nprint(f\"Best params: {best_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T05:07:37.779907Z","iopub.execute_input":"2025-05-19T05:07:37.780688Z","iopub.status.idle":"2025-05-19T05:55:05.460262Z","shell.execute_reply.started":"2025-05-19T05:07:37.780659Z","shell.execute_reply":"2025-05-19T05:55:05.459518Z"}},"outputs":[{"name":"stdout","text":"Trial 1/20: {'n_blocks': 3, 'n_columns': 4, 'out_channels': [32, 64, 128], 'local_drop_prob': 0.5, 'drop_prob': 0.5, 'global_drop_prob': 0.5, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nTotal layers in network: 24\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.5047, Recall: 0.5115, F1: 0.4994\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.5000, Recall: 0.5140, F1: 0.4728\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.4832, Recall: 0.4724, F1: 0.3438\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 2/20: {'n_blocks': 3, 'n_columns': 2, 'out_channels': [64, 128, 256], 'local_drop_prob': 0.3, 'drop_prob': 0.0, 'global_drop_prob': 0.5, 'dropout': 0.1, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 64\nBlock 2, Input channels: 64, Output channels: 128\nBlock 3, Input channels: 128, Output channels: 256\nTotal layers in network: 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4995, Recall: 0.4978, F1: 0.4982\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.8853, Recall: 0.8845, F1: 0.8846\n  Val Precision: 0.5277, Recall: 0.4804, F1: 0.4644\nEpoch 100/100:\n  Train Precision: 0.9814, Recall: 0.9814, F1: 0.9814\n  Val Precision: 0.5243, Recall: 0.5251, F1: 0.5247\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4324    0.4267    0.4295        75\n           1     0.5905    0.5962    0.5933       104\n\n    accuracy                         0.5251       179\n   macro avg     0.5115    0.5114    0.5114       179\nweighted avg     0.5243    0.5251    0.5247       179\n\nValidation accuracy: 0.5251\nTrial 3/20: {'n_blocks': 3, 'n_columns': 2, 'out_channels': [32, 64, 128], 'local_drop_prob': 0.3, 'drop_prob': 0.4, 'global_drop_prob': 0.1, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nTotal layers in network: 6\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.5224, Recall: 0.5239, F1: 0.5227\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.5785, Recall: 0.5568, F1: 0.5432\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.8336, Recall: 0.8324, F1: 0.8325\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 4/20: {'n_blocks': 2, 'n_columns': 3, 'out_channels': [16, 32], 'local_drop_prob': 0.3, 'drop_prob': 0.3, 'global_drop_prob': 0.1, 'dropout': 0.0, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.7513, Recall: 0.4755, F1: 0.3092\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4898, Recall: 0.4873, F1: 0.4874\n  Val Precision: 0.4481, Recall: 0.4190, F1: 0.4090\nEpoch 100/100:\n  Train Precision: 0.5034, Recall: 0.5071, F1: 0.5027\n  Val Precision: 0.5394, Recall: 0.5642, F1: 0.5310\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4634    0.2533    0.3276        75\n           1     0.5942    0.7885    0.6777       104\n\n    accuracy                         0.5642       179\n   macro avg     0.5288    0.5209    0.5026       179\nweighted avg     0.5394    0.5642    0.5310       179\n\nValidation accuracy: 0.5642\nTrial 5/20: {'n_blocks': 2, 'n_columns': 4, 'out_channels': [32, 64], 'local_drop_prob': 0.3, 'drop_prob': 0.1, 'global_drop_prob': 0.0, 'dropout': 0.3, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4882, Recall: 0.4879, F1: 0.4880\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4948, Recall: 0.4922, F1: 0.4924\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.4959, Recall: 0.4978, F1: 0.4963\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 6/20: {'n_blocks': 3, 'n_columns': 2, 'out_channels': [32, 64, 128], 'local_drop_prob': 0.5, 'drop_prob': 0.3, 'global_drop_prob': 0.1, 'dropout': 0.3, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nTotal layers in network: 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4605, Recall: 0.4556, F1: 0.4316\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.4973, Recall: 0.5102, F1: 0.4779\n  Val Precision: 0.7575, Recall: 0.4246, F1: 0.2595\nEpoch 100/100:\n  Train Precision: 0.5067, Recall: 0.5016, F1: 0.4997\n  Val Precision: 0.5251, Recall: 0.5363, F1: 0.5280\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4355    0.3600    0.3942        75\n           1     0.5897    0.6635    0.6244       104\n\n    accuracy                         0.5363       179\n   macro avg     0.5126    0.5117    0.5093       179\nweighted avg     0.5251    0.5363    0.5280       179\n\nValidation accuracy: 0.5363\nTrial 7/20: {'n_blocks': 2, 'n_columns': 4, 'out_channels': [64, 128], 'local_drop_prob': 0.5, 'drop_prob': 0.3, 'global_drop_prob': 0.0, 'dropout': 0.0, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 64\nBlock 2, Input channels: 64, Output channels: 128\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4722, Recall: 0.4755, F1: 0.4726\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.5254, Recall: 0.5245, F1: 0.5248\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.5493, Recall: 0.5382, F1: 0.5320\n  Val Precision: 0.4842, Recall: 0.5587, F1: 0.4575\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.3571    0.0667    0.1124        75\n           1     0.5758    0.9135    0.7063       104\n\n    accuracy                         0.5587       179\n   macro avg     0.4665    0.4901    0.4093       179\nweighted avg     0.4842    0.5587    0.4575       179\n\nValidation accuracy: 0.5587\nTrial 8/20: {'n_blocks': 2, 'n_columns': 4, 'out_channels': [16, 32], 'local_drop_prob': 0.5, 'drop_prob': 0.5, 'global_drop_prob': 0.0, 'dropout': 0.0, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.5200, Recall: 0.4966, F1: 0.4527\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4923, Recall: 0.4960, F1: 0.4921\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.5131, Recall: 0.5251, F1: 0.4559\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 9/20: {'n_blocks': 4, 'n_columns': 2, 'out_channels': [32, 64, 128, 256], 'local_drop_prob': 0.5, 'drop_prob': 0.1, 'global_drop_prob': 0.0, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4960, Recall: 0.4947, F1: 0.4951\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.5040, Recall: 0.5022, F1: 0.5025\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.4851, Recall: 0.4891, F1: 0.4850\n  Val Precision: 0.5084, Recall: 0.5084, F1: 0.5084\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4133    0.4133    0.4133        75\n           1     0.5769    0.5769    0.5769       104\n\n    accuracy                         0.5084       179\n   macro avg     0.4951    0.4951    0.4951       179\nweighted avg     0.5084    0.5084    0.5084       179\n\nValidation accuracy: 0.5084\nTrial 10/20: {'n_blocks': 4, 'n_columns': 2, 'out_channels': [64, 128, 256, 512], 'local_drop_prob': 0.5, 'drop_prob': 0.3, 'global_drop_prob': 0.3, 'dropout': 0.0, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 64\nBlock 2, Input channels: 64, Output channels: 128\nBlock 3, Input channels: 128, Output channels: 256\nBlock 4, Input channels: 256, Output channels: 512\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4860, Recall: 0.4730, F1: 0.3678\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4808, Recall: 0.4786, F1: 0.4788\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.4917, Recall: 0.4836, F1: 0.4736\n  Val Precision: 0.4986, Recall: 0.5587, F1: 0.4709\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.3889    0.0933    0.1505        75\n           1     0.5776    0.8942    0.7019       104\n\n    accuracy                         0.5587       179\n   macro avg     0.4833    0.4938    0.4262       179\nweighted avg     0.4986    0.5587    0.4709       179\n\nValidation accuracy: 0.5587\nTrial 11/20: {'n_blocks': 3, 'n_columns': 4, 'out_channels': [16, 32, 64], 'local_drop_prob': 0.3, 'drop_prob': 0.3, 'global_drop_prob': 0.0, 'dropout': 0.1, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nBlock 3, Input channels: 32, Output channels: 64\nTotal layers in network: 24\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.2777, Recall: 0.5270, F1: 0.3638\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.4995, Recall: 0.5102, F1: 0.4854\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.5152, Recall: 0.5220, F1: 0.5058\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 12/20: {'n_blocks': 2, 'n_columns': 4, 'out_channels': [16, 32], 'local_drop_prob': 0.3, 'drop_prob': 0.3, 'global_drop_prob': 0.3, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4739, Recall: 0.4724, F1: 0.4728\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4575, Recall: 0.4718, F1: 0.3118\n  Val Precision: 0.5589, Recall: 0.4581, F1: 0.3803\nEpoch 100/100:\n  Train Precision: 0.5050, Recall: 0.5084, F1: 0.5047\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4190    1.0000    0.5906        75\n           1     0.0000    0.0000    0.0000       104\n\n    accuracy                         0.4190       179\n   macro avg     0.2095    0.5000    0.2953       179\nweighted avg     0.1756    0.4190    0.2474       179\n\nValidation accuracy: 0.4190\nTrial 13/20: {'n_blocks': 4, 'n_columns': 3, 'out_channels': [16, 32, 64, 128], 'local_drop_prob': 0.0, 'drop_prob': 0.1, 'global_drop_prob': 0.0, 'dropout': 0.0, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nBlock 3, Input channels: 32, Output channels: 64\nBlock 4, Input channels: 64, Output channels: 128\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4822, Recall: 0.4848, F1: 0.4826\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.7975, Recall: 0.7976, F1: 0.7975\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.9442, Recall: 0.9441, F1: 0.9441\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 14/20: {'n_blocks': 3, 'n_columns': 3, 'out_channels': [16, 32, 64], 'local_drop_prob': 0.5, 'drop_prob': 0.3, 'global_drop_prob': 0.1, 'dropout': 0.3, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nBlock 3, Input channels: 32, Output channels: 64\nTotal layers in network: 12\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4663, Recall: 0.5239, F1: 0.3730\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.5136, Recall: 0.5171, F1: 0.5127\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.5180, Recall: 0.5127, F1: 0.5111\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 15/20: {'n_blocks': 4, 'n_columns': 3, 'out_channels': [32, 64, 128, 256], 'local_drop_prob': 0.5, 'drop_prob': 0.4, 'global_drop_prob': 0.4, 'dropout': 0.3, 'lr': 0.0001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.5146, Recall: 0.5102, F1: 0.5093\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.4953, Recall: 0.4904, F1: 0.4885\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.5025, Recall: 0.5028, F1: 0.5026\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 16/20: {'n_blocks': 4, 'n_columns': 3, 'out_channels': [64, 128, 256, 512], 'local_drop_prob': 0.5, 'drop_prob': 0.1, 'global_drop_prob': 0.4, 'dropout': 0.0, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 64\nBlock 2, Input channels: 64, Output channels: 128\nBlock 3, Input channels: 128, Output channels: 256\nBlock 4, Input channels: 256, Output channels: 512\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4915, Recall: 0.5071, F1: 0.4688\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.5108, Recall: 0.5158, F1: 0.5078\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.5133, Recall: 0.5152, F1: 0.5136\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 17/20: {'n_blocks': 4, 'n_columns': 2, 'out_channels': [32, 64, 128, 256], 'local_drop_prob': 0.5, 'drop_prob': 0.4, 'global_drop_prob': 0.3, 'dropout': 0.0, 'lr': 1e-05, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.2237, Recall: 0.4730, F1: 0.3038\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.5053, Recall: 0.5003, F1: 0.4987\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.5294, Recall: 0.5196, F1: 0.5130\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4190    1.0000    0.5906        75\n           1     0.0000    0.0000    0.0000       104\n\n    accuracy                         0.4190       179\n   macro avg     0.2095    0.5000    0.2953       179\nweighted avg     0.1756    0.4190    0.2474       179\n\nValidation accuracy: 0.4190\nTrial 18/20: {'n_blocks': 3, 'n_columns': 4, 'out_channels': [64, 128, 256], 'local_drop_prob': 0.5, 'drop_prob': 0.0, 'global_drop_prob': 0.1, 'dropout': 0.3, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 64\nBlock 2, Input channels: 64, Output channels: 128\nBlock 3, Input channels: 128, Output channels: 256\nTotal layers in network: 24\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4890, Recall: 0.4891, F1: 0.4891\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/100:\n  Train Precision: 0.4877, Recall: 0.4947, F1: 0.4847\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 100/100:\n  Train Precision: 0.4879, Recall: 0.4836, F1: 0.4821\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 19/20: {'n_blocks': 3, 'n_columns': 3, 'out_channels': [16, 32, 64], 'local_drop_prob': 0.0, 'drop_prob': 0.5, 'global_drop_prob': 0.1, 'dropout': 0.0, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 16\nBlock 2, Input channels: 16, Output channels: 32\nBlock 3, Input channels: 32, Output channels: 64\nTotal layers in network: 12\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.4801, Recall: 0.4711, F1: 0.4424\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.6679, Recall: 0.6214, F1: 0.6037\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 100/100:\n  Train Precision: 0.8579, Recall: 0.8572, F1: 0.8573\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\nTrial 20/20: {'n_blocks': 4, 'n_columns': 3, 'out_channels': [32, 64, 128, 256], 'local_drop_prob': 0.0, 'drop_prob': 0.1, 'global_drop_prob': 0.5, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\nBlock 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100:\n  Train Precision: 0.5075, Recall: 0.5078, F1: 0.5076\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nEpoch 50/100:\n  Train Precision: 0.4962, Recall: 0.5146, F1: 0.4555\n  Val Precision: 0.5179, Recall: 0.5642, F1: 0.4866\nEpoch 100/100:\n  Train Precision: 0.2777, Recall: 0.5270, F1: 0.3638\n  Val Precision: 0.3376, Recall: 0.5810, F1: 0.4270\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000        75\n           1     0.5810    1.0000    0.7350       104\n\n    accuracy                         0.5810       179\n   macro avg     0.2905    0.5000    0.3675       179\nweighted avg     0.3376    0.5810    0.4270       179\n\nValidation accuracy: 0.5810\n\nBest accuracy: 0.5810\nBest params: {'n_blocks': 3, 'n_columns': 4, 'out_channels': [32, 64, 128], 'local_drop_prob': 0.5, 'drop_prob': 0.5, 'global_drop_prob': 0.5, 'dropout': 0.1, 'lr': 0.001, 'kernel_size': 3, 'embedding_dim': 300}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"seed_everything(0)\nembedding_dim=300\nn_blocks= 4\nn_columns= 2\nout_channels = [32, 64, 128, 256]\nkernel_size= 3\nlocal_drop_prob=0.5\ndrop_prob=0.1\nglobal_drop_prob=0.3\nmlp_hidden_dims=[256, 256]\ndropout=0.2\n\n\nnum_epoch = 150\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = NewsModel(\n        embedding_dim=embedding_dim,\n        n_blocks=n_blocks,\n        n_columns=n_columns,\n        out_channels=out_channels,\n        kernel_size=kernel_size,\n        local_drop_prob=local_drop_prob,\n        drop_prob=drop_prob,\n        global_drop_prob=global_drop_prob,\n        mlp_hidden_dims=mlp_hidden_dims,\n        dropout=dropout,\n    ).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\nclass_weights = class_weights.to(device)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\nnews, labels, masks = combine_embeddings(df, fasttext_model, 3, 32)\ntrain_loader, val_loader, test_loader, class_weights, encoder = prepare_dataloaders(news, masks, labels)\n\ntrain(model, train_loader, val_loader, num_epoch, optimizer=optimizer,\n          criterion=criterion, device=device) \n\ntest_model(model, test_loader, device, 'fractal.png')\ntorch.save(model.state_dict(), 'fractal-attn.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:22:17.968289Z","iopub.execute_input":"2025-05-19T07:22:17.968840Z","iopub.status.idle":"2025-05-19T07:24:39.108933Z","shell.execute_reply.started":"2025-05-19T07:22:17.968818Z","shell.execute_reply":"2025-05-19T07:24:39.108169Z"}},"outputs":[{"name":"stdout","text":"Block 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/150:\n  Train Precision: 0.5027, Recall: 0.5022, F1: 0.5024\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/150:\n  Train Precision: 0.4912, Recall: 0.5016, F1: 0.4822\n  Val Precision: 0.3334, Recall: 0.5642, F1: 0.4192\nEpoch 100/150:\n  Train Precision: 0.5104, Recall: 0.5034, F1: 0.4993\n  Val Precision: 0.5329, Recall: 0.5754, F1: 0.4746\nEpoch 150/150:\n  Train Precision: 0.5261, Recall: 0.5326, F1: 0.4968\n  Val Precision: 0.5498, Recall: 0.5810, F1: 0.4707\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.58      0.13      0.21        87\n           1       0.58      0.93      0.71       112\n\n    accuracy                           0.58       199\n   macro avg       0.58      0.53      0.46       199\nweighted avg       0.58      0.58      0.49       199\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"seed_everything(0)\nembedding_dim=300\nn_blocks= 4\nn_columns= 2\nout_channels = [32, 64, 128, 256]\nkernel_size= 3\nlocal_drop_prob=0.5\ndrop_prob=0.1\nglobal_drop_prob=0.3\nmlp_hidden_dims=[256, 256]\ndropout=0.2\n\n\nnum_epoch = 200\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = NewsModel(\n        embedding_dim=embedding_dim,\n        n_blocks=n_blocks,\n        n_columns=n_columns,\n        out_channels=out_channels,\n        kernel_size=kernel_size,\n        local_drop_prob=local_drop_prob,\n        drop_prob=drop_prob,\n        global_drop_prob=global_drop_prob,\n        mlp_hidden_dims=mlp_hidden_dims,\n        dropout=dropout,\n    ).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\nclass_weights = class_weights.to(device)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\nnews, labels, masks = combine_embeddings(df, fasttext_model, 3, 32)\ntrain_loader, val_loader, test_loader, class_weights, encoder = prepare_dataloaders(news, masks, labels)\n\ntrain(model, train_loader, val_loader, num_epoch, optimizer=optimizer,\n          criterion=criterion, device=device) \n\ntest_model(model, test_loader, device, 'fractal.png')\ntorch.save(model.state_dict(), 'fractal-attn.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:26:38.987528Z","iopub.execute_input":"2025-05-19T07:26:38.988276Z","iopub.status.idle":"2025-05-19T07:29:44.649408Z","shell.execute_reply.started":"2025-05-19T07:26:38.988225Z","shell.execute_reply":"2025-05-19T07:29:44.648637Z"}},"outputs":[{"name":"stdout","text":"Block 1, Input channels: 300, Output channels: 32\nBlock 2, Input channels: 32, Output channels: 64\nBlock 3, Input channels: 64, Output channels: 128\nBlock 4, Input channels: 128, Output channels: 256\nTotal layers in network: 8\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3688444839.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  text = row[idx]\n/tmp/ipykernel_31/3688444839.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  labels.append(row[1])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200:\n  Train Precision: 0.5027, Recall: 0.5022, F1: 0.5024\n  Val Precision: 0.1756, Recall: 0.4190, F1: 0.2474\nEpoch 50/200:\n  Train Precision: 0.4912, Recall: 0.5016, F1: 0.4822\n  Val Precision: 0.3334, Recall: 0.5642, F1: 0.4192\nEpoch 100/200:\n  Train Precision: 0.5104, Recall: 0.5034, F1: 0.4993\n  Val Precision: 0.5329, Recall: 0.5754, F1: 0.4746\nEpoch 150/200:\n  Train Precision: 0.5261, Recall: 0.5326, F1: 0.4968\n  Val Precision: 0.5498, Recall: 0.5810, F1: 0.4707\nEpoch 200/200:\n  Train Precision: 0.4954, Recall: 0.5109, F1: 0.4688\n  Val Precision: 0.5267, Recall: 0.5196, F1: 0.5221\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.56      0.44      0.49        87\n           1       0.63      0.73      0.67       112\n\n    accuracy                           0.60       199\n   macro avg       0.59      0.58      0.58       199\nweighted avg       0.60      0.60      0.59       199\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stocknews/Combined_News_DJIA.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:25:11.747166Z","iopub.execute_input":"2025-05-19T08:25:11.747688Z","iopub.status.idle":"2025-05-19T08:25:11.851689Z","shell.execute_reply.started":"2025-05-19T08:25:11.747665Z","shell.execute_reply":"2025-05-19T08:25:11.850952Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"         Date  Label                                               Top1  \\\n0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n4  2008-08-14      1  b'All the experts admit that we should legalis...   \n\n                                                Top2  \\\n0            b'BREAKING: Musharraf to be impeached.'   \n1        b'Bush puts foot down on Georgian conflict'   \n2                 b\"Russia 'ends Georgia operation'\"   \n3  b\"When the president ordered to attack Tskhinv...   \n4  b'War in South Osetia - 89 pictures made by a ...   \n\n                                                Top3  \\\n0  b'Russia Today: Columns of troops roll into So...   \n1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n2  b'\"If we had no sexual harassment we would hav...   \n3  b' Israel clears troops who killed Reuters cam...   \n4  b'Swedish wrestler Ara Abrahamian throws away ...   \n\n                                                Top4  \\\n0  b'Russian tanks are moving towards the capital...   \n1  b'Georgian army flees in disarray as Russians ...   \n2  b\"Al-Qa'eda is losing support in Iraq because ...   \n3  b'Britain\\'s policy of being tough on drugs is...   \n4  b'Russia exaggerated the death toll in South O...   \n\n                                                Top5  \\\n0  b\"Afghan children raped with 'impunity,' U.N. ...   \n1      b\"Olympic opening ceremony fireworks 'faked'\"   \n2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n3  b'Body of 14 year old found in trunk; Latest (...   \n4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n\n                                                Top6  \\\n0  b'150 Russian tanks have entered South Ossetia...   \n1  b'What were the Mossad with fraudulent New Zea...   \n2  b'Why Microsoft and Intel tried to kill the XO...   \n3  b'China has moved 10 *million* quake survivors...   \n4  b\"Rushdie Condemns Random House's Refusal to P...   \n\n                                                Top7  \\\n0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n1  b'Russia angered by Israeli military sale to G...   \n2  b'Stratfor: The Russo-Georgian War and the Bal...   \n3  b\"Bush announces Operation Get All Up In Russi...   \n4  b'Poland and US agree to missle defense deal. ...   \n\n                                                Top8  ...  \\\n0  b\"The 'enemy combatent' trials are nothing but...  ...   \n1  b'An American citizen living in S.Ossetia blam...  ...   \n2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n3             b'Russian forces sink Georgian ships '  ...   \n4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n\n                                               Top16  \\\n0  b'Georgia Invades South Ossetia - if Russia ge...   \n1  b'Israel and the US behind the Georgian aggres...   \n2  b'U.S. troops still in Georgia (did you know t...   \n3                      b'Elephants extinct by 2020?'   \n4  b'Bank analyst forecast Georgian crisis 2 days...   \n\n                                               Top17  \\\n0                b'Al-Qaeda Faces Islamist Backlash'   \n1  b'\"Do not believe TV, neither Russian nor Geor...   \n2       b'Why Russias response to Georgia was right'   \n3  b'US humanitarian missions soon in Georgia - i...   \n4  b\"Georgia confict could set back Russia's US r...   \n\n                                               Top18  \\\n0  b'Condoleezza Rice: \"The US would not act to p...   \n1  b'Riots are still going on in Montreal (Canada...   \n2  b'Gorbachev accuses U.S. of making a \"serious ...   \n3             b\"Georgia's DDOS came from US sources\"   \n4  b'War in the Caucasus is as much the product o...   \n\n                                               Top19  \\\n0  b'This is a busy day:  The European Union has ...   \n1    b'China to overtake US as largest manufacturer'   \n2         b'Russia, Georgia, and NATO: Cold War Two'   \n3  b'Russian convoy heads into Georgia, violating...   \n4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n\n                                               Top20  \\\n0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n1                     b'War in South Ossetia [PICS]'   \n2  b'Remember that adorable 62-year-old who led y...   \n3  b'Israeli defence minister: US against strike ...   \n4  b'Georgian TV reporter shot by Russian sniper ...   \n\n                                               Top21  \\\n0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n1  b'Israeli Physicians Group Condemns State Tort...   \n2          b'War in Georgia: The Israeli connection'   \n3                     b'Gorbachev: We Had No Choice'   \n4  b'Saudi Arabia: Mother moves to block child ma...   \n\n                                               Top22  \\\n0  b'Caucasus in crisis: Georgia invades South Os...   \n1  b' Russia has just beaten the United States ov...   \n2  b'All signs point to the US encouraging Georgi...   \n3  b'Witness: Russian forces head towards Tbilisi...   \n4   b'Taliban wages war on humanitarian aid workers'   \n\n                                               Top23  \\\n0  b'Indian shoe manufactory  - And again in a se...   \n1  b'Perhaps *the* question about the Georgia - R...   \n2  b'Christopher King argues that the US and NATO...   \n3  b' Quarter of Russians blame U.S. for conflict...   \n4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n\n                                               Top24  \\\n0  b'Visitors Suffering from Mental Illnesses Ban...   \n1                 b'Russia is so much better at war'   \n2                        b'America: The New Mexico?'   \n3  b'Georgian president  says US military will ta...   \n4  b'Darfur rebels accuse Sudan of mounting major...   \n\n                                               Top25  \n0           b\"No Help for Mexico's Kidnapping Surge\"  \n1  b\"So this is what it's come to: trading sex fo...  \n2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n4  b'Philippines : Peace Advocate say Muslims nee...  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Label</th>\n      <th>Top1</th>\n      <th>Top2</th>\n      <th>Top3</th>\n      <th>Top4</th>\n      <th>Top5</th>\n      <th>Top6</th>\n      <th>Top7</th>\n      <th>Top8</th>\n      <th>...</th>\n      <th>Top16</th>\n      <th>Top17</th>\n      <th>Top18</th>\n      <th>Top19</th>\n      <th>Top20</th>\n      <th>Top21</th>\n      <th>Top22</th>\n      <th>Top23</th>\n      <th>Top24</th>\n      <th>Top25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-08-08</td>\n      <td>0</td>\n      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n      <td>b'BREAKING: Musharraf to be impeached.'</td>\n      <td>b'Russia Today: Columns of troops roll into So...</td>\n      <td>b'Russian tanks are moving towards the capital...</td>\n      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n      <td>b'150 Russian tanks have entered South Ossetia...</td>\n      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n      <td>...</td>\n      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n      <td>b'This is a busy day:  The European Union has ...</td>\n      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n      <td>b'Indian shoe manufactory  - And again in a se...</td>\n      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-08-11</td>\n      <td>1</td>\n      <td>b'Why wont America and Nato help us? If they w...</td>\n      <td>b'Bush puts foot down on Georgian conflict'</td>\n      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n      <td>b'Georgian army flees in disarray as Russians ...</td>\n      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n      <td>b'What were the Mossad with fraudulent New Zea...</td>\n      <td>b'Russia angered by Israeli military sale to G...</td>\n      <td>b'An American citizen living in S.Ossetia blam...</td>\n      <td>...</td>\n      <td>b'Israel and the US behind the Georgian aggres...</td>\n      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n      <td>b'Riots are still going on in Montreal (Canada...</td>\n      <td>b'China to overtake US as largest manufacturer'</td>\n      <td>b'War in South Ossetia [PICS]'</td>\n      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n      <td>b' Russia has just beaten the United States ov...</td>\n      <td>b'Perhaps *the* question about the Georgia - R...</td>\n      <td>b'Russia is so much better at war'</td>\n      <td>b\"So this is what it's come to: trading sex fo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-08-12</td>\n      <td>0</td>\n      <td>b'Remember that adorable 9-year-old who sang a...</td>\n      <td>b\"Russia 'ends Georgia operation'\"</td>\n      <td>b'\"If we had no sexual harassment we would hav...</td>\n      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n      <td>...</td>\n      <td>b'U.S. troops still in Georgia (did you know t...</td>\n      <td>b'Why Russias response to Georgia was right'</td>\n      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n      <td>b'Remember that adorable 62-year-old who led y...</td>\n      <td>b'War in Georgia: The Israeli connection'</td>\n      <td>b'All signs point to the US encouraging Georgi...</td>\n      <td>b'Christopher King argues that the US and NATO...</td>\n      <td>b'America: The New Mexico?'</td>\n      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-08-13</td>\n      <td>0</td>\n      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n      <td>b\"When the president ordered to attack Tskhinv...</td>\n      <td>b' Israel clears troops who killed Reuters cam...</td>\n      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n      <td>b'China has moved 10 *million* quake survivors...</td>\n      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n      <td>b'Russian forces sink Georgian ships '</td>\n      <td>...</td>\n      <td>b'Elephants extinct by 2020?'</td>\n      <td>b'US humanitarian missions soon in Georgia - i...</td>\n      <td>b\"Georgia's DDOS came from US sources\"</td>\n      <td>b'Russian convoy heads into Georgia, violating...</td>\n      <td>b'Israeli defence minister: US against strike ...</td>\n      <td>b'Gorbachev: We Had No Choice'</td>\n      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n      <td>b'Georgian president  says US military will ta...</td>\n      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-08-14</td>\n      <td>1</td>\n      <td>b'All the experts admit that we should legalis...</td>\n      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n      <td>b'Russia exaggerated the death toll in South O...</td>\n      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n      <td>b'Poland and US agree to missle defense deal. ...</td>\n      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n      <td>...</td>\n      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n      <td>b\"Georgia confict could set back Russia's US r...</td>\n      <td>b'War in the Caucasus is as much the product o...</td>\n      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n      <td>b'Taliban wages war on humanitarian aid workers'</td>\n      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"def prepare_bert_inputs_from_news(df, news_cols, label_col, num_headlines=3, max_len_each=32, batch_size=32, test_size=0.1, val_size=0.1):\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n    input_ids_list = []\n    attention_masks_list = []\n    labels_list = []\n\n    for _, row in df.iterrows():\n        input_ids_news = []\n        attention_masks_news = []\n        \n        for col in news_cols[:num_headlines]:\n            tokens = tokenizer(\n                str(row[col]),\n                add_special_tokens=True,\n                max_length=max_len_each,\n                padding='max_length',\n                truncation=True,\n                return_attention_mask=True,\n                return_tensors='pt'\n            )\n            input_ids_news.append(tokens['input_ids'].squeeze(0))\n            attention_masks_news.append(tokens['attention_mask'].squeeze(0))\n        \n        input_ids_combined = torch.cat(input_ids_news)\n        attention_masks_combined = torch.cat(attention_masks_news)\n\n        input_ids_list.append(input_ids_combined)\n        attention_masks_list.append(attention_masks_combined)\n        labels_list.append(row[label_col])\n\n    input_ids = torch.stack(input_ids_list)\n    attention_masks = torch.stack(attention_masks_list)\n    labels = torch.tensor(labels_list)\n\n    X_temp, X_test, y_temp, y_test, mask_temp, mask_test = train_test_split(\n        input_ids, labels, attention_masks, test_size=test_size, random_state=42\n    )\n\n    val_ratio = val_size / (1 - test_size)\n\n    X_train, X_val, y_train, y_val, mask_train, mask_val = train_test_split(\n        X_temp, y_temp, mask_temp, test_size=val_ratio, random_state=42\n    )\n\n    train_data = TensorDataset(X_train, mask_train, y_train)\n    val_data = TensorDataset(X_val, mask_val, y_val)\n    test_data = TensorDataset(X_test, mask_test, y_test)\n\n    train_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n    val_loader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)\n    test_loader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n\n    return train_loader, val_loader, test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:04:00.653629Z","iopub.execute_input":"2025-05-19T09:04:00.654466Z","iopub.status.idle":"2025-05-19T09:04:00.663670Z","shell.execute_reply.started":"2025-05-19T09:04:00.654436Z","shell.execute_reply":"2025-05-19T09:04:00.662897Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"news_columns = [f'Top{i}' for i in range(1, 26)]\ntrain_loader, val_loader, test_loader = prepare_bert_inputs_from_news(\n    df=df,\n    news_cols=news_columns,\n    label_col='Label',\n    num_headlines=3,  \n    max_len_each=32,    \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:04:04.386381Z","iopub.execute_input":"2025-05-19T09:04:04.387104Z","iopub.status.idle":"2025-05-19T09:04:08.095786Z","shell.execute_reply.started":"2025-05-19T09:04:04.387079Z","shell.execute_reply":"2025-05-19T09:04:08.095173Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:45:08.522203Z","iopub.execute_input":"2025-05-19T08:45:08.522526Z","iopub.status.idle":"2025-05-19T08:45:09.864758Z","shell.execute_reply.started":"2025-05-19T08:45:08.522498Z","shell.execute_reply":"2025-05-19T08:45:09.864135Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1)\n    labels_flat = labels\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n\ndef train_model(model, train_loader, val_loader, epochs=4, lr=2e-5):\n    all_labels = []\n    for batch in train_loader:\n        _, _, b_labels = batch\n        all_labels.extend(b_labels.numpy())\n    all_labels = np.array(all_labels)\n\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(all_labels),\n        y=all_labels\n    )\n    weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n    \n    loss_fct = nn.CrossEntropyLoss(weight=weights)\n\n    optimizer = AdamW(model.parameters(), lr=lr)\n    total_steps = len(train_loader) * epochs\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n    )\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n\n            model.zero_grad()\n            outputs = model(\n                input_ids=b_input_ids,\n                attention_mask=b_input_mask,\n            )\n            logits = outputs.logits\n\n            loss = loss_fct(logits, b_labels)\n\n            total_loss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_loss / len(train_loader)\n\n        model.eval()\n        val_accuracy = 0\n        nb_val_steps = 0\n\n        for batch in val_loader:\n            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n\n            with torch.no_grad():\n                outputs = model(\n                    input_ids=b_input_ids,\n                    attention_mask=b_input_mask\n                )\n                logits = outputs.logits\n\n            logits = logits.detach().cpu().numpy()\n            label_ids = b_labels.cpu().numpy()\n\n            val_accuracy += flat_accuracy(logits, label_ids)\n            nb_val_steps += 1\n\n        print(f\"\\nEpoch {epoch+1}\")\n        print(f\"Train loss: {avg_train_loss:.4f}\")\n        print(f\"Validation accuracy: {val_accuracy / nb_val_steps:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:53:56.576084Z","iopub.execute_input":"2025-05-19T08:53:56.576384Z","iopub.status.idle":"2025-05-19T08:53:56.585844Z","shell.execute_reply.started":"2025-05-19T08:53:56.576362Z","shell.execute_reply":"2025-05-19T08:53:56.585057Z"}},"outputs":[],"execution_count":125},{"cell_type":"code","source":"def test_model(model, test_loader, name):\n    model.eval()\n    predictions = []\n    true_labels = []\n\n    for batch in test_loader:\n        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n\n        with torch.no_grad():\n            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n            logits = outputs.logits\n\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        label_ids = b_labels.cpu().numpy()\n\n        predictions.extend(preds)\n        true_labels.extend(label_ids)\n\n    predictions = np.array(predictions)\n    true_labels = np.array(true_labels)\n    accuracy = np.sum(predictions == true_labels) / len(true_labels)\n    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(true_labels, predictions))\n\n    cm = confusion_matrix(true_labels, predictions)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(name, dpi=300, bbox_inches='tight')  \n    plt.show()\n\n    return predictions, true_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:50:12.250387Z","iopub.execute_input":"2025-05-19T08:50:12.251066Z","iopub.status.idle":"2025-05-19T08:50:12.257039Z","shell.execute_reply.started":"2025-05-19T08:50:12.251041Z","shell.execute_reply":"2025-05-19T08:50:12.256372Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:04:55.700045Z","iopub.execute_input":"2025-05-19T09:04:55.700338Z","iopub.status.idle":"2025-05-19T09:05:11.545040Z","shell.execute_reply.started":"2025-05-19T09:04:55.700316Z","shell.execute_reply":"2025-05-19T09:05:11.544378Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.6995\nValidation accuracy: 0.5415\n","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:05:11.546485Z","iopub.execute_input":"2025-05-19T09:05:11.546673Z","iopub.status.idle":"2025-05-19T09:05:42.714832Z","shell.execute_reply.started":"2025-05-19T09:05:11.546658Z","shell.execute_reply":"2025-05-19T09:05:42.714009Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7043\nValidation accuracy: 0.5230\n\nEpoch 2\nTrain loss: 0.6938\nValidation accuracy: 0.5230\n","output_type":"stream"}],"execution_count":138},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:05:42.716190Z","iopub.execute_input":"2025-05-19T09:05:42.716629Z","iopub.status.idle":"2025-05-19T09:06:28.883697Z","shell.execute_reply.started":"2025-05-19T09:05:42.716609Z","shell.execute_reply":"2025-05-19T09:06:28.882953Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7055\nValidation accuracy: 0.4388\n\nEpoch 2\nTrain loss: 0.6914\nValidation accuracy: 0.5300\n\nEpoch 3\nTrain loss: 0.6788\nValidation accuracy: 0.5121\n","output_type":"stream"}],"execution_count":139},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:06:28.885228Z","iopub.execute_input":"2025-05-19T09:06:28.885489Z","iopub.status.idle":"2025-05-19T09:07:30.166951Z","shell.execute_reply.started":"2025-05-19T09:06:28.885471Z","shell.execute_reply":"2025-05-19T09:07:30.166291Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7020\nValidation accuracy: 0.4432\n\nEpoch 2\nTrain loss: 0.6944\nValidation accuracy: 0.5459\n\nEpoch 3\nTrain loss: 0.6855\nValidation accuracy: 0.5619\n\nEpoch 4\nTrain loss: 0.6608\nValidation accuracy: 0.5415\n","output_type":"stream"}],"execution_count":140},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:08:04.495739Z","iopub.execute_input":"2025-05-19T09:08:04.496503Z","iopub.status.idle":"2025-05-19T09:09:21.004850Z","shell.execute_reply.started":"2025-05-19T09:08:04.496464Z","shell.execute_reply":"2025-05-19T09:09:21.004089Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7098\nValidation accuracy: 0.5344\n\nEpoch 2\nTrain loss: 0.6928\nValidation accuracy: 0.5210\n\nEpoch 3\nTrain loss: 0.6625\nValidation accuracy: 0.4923\n\nEpoch 4\nTrain loss: 0.5881\nValidation accuracy: 0.5102\n\nEpoch 5\nTrain loss: 0.4905\nValidation accuracy: 0.5147\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:09:48.724863Z","iopub.execute_input":"2025-05-19T09:09:48.725479Z","iopub.status.idle":"2025-05-19T09:11:20.386049Z","shell.execute_reply.started":"2025-05-19T09:09:48.725457Z","shell.execute_reply":"2025-05-19T09:11:20.385289Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7034\nValidation accuracy: 0.5548\n\nEpoch 2\nTrain loss: 0.6925\nValidation accuracy: 0.5102\n\nEpoch 3\nTrain loss: 0.6779\nValidation accuracy: 0.5102\n\nEpoch 4\nTrain loss: 0.6096\nValidation accuracy: 0.5274\n\nEpoch 5\nTrain loss: 0.4998\nValidation accuracy: 0.5364\n\nEpoch 6\nTrain loss: 0.4162\nValidation accuracy: 0.5319\n","output_type":"stream"}],"execution_count":142},{"cell_type":"code","source":"num_labels = 2 \nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\nmodel.to(device)\ntrain_model(model, train_loader, val_loader, epochs=3)\npreds, labels = test_model(model, test_loader, 'bert.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:13:58.590838Z","iopub.execute_input":"2025-05-19T09:13:58.591107Z","iopub.status.idle":"2025-05-19T09:14:45.731876Z","shell.execute_reply.started":"2025-05-19T09:13:58.591088Z","shell.execute_reply":"2025-05-19T09:14:45.731108Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain loss: 0.7017\nValidation accuracy: 0.5421\n\nEpoch 2\nTrain loss: 0.6897\nValidation accuracy: 0.5619\n\nEpoch 3\nTrain loss: 0.6674\nValidation accuracy: 0.5261\n\nTest Accuracy: 0.5276\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0       0.47      0.64      0.54        87\n           1       0.61      0.44      0.51       112\n\n    accuracy                           0.53       199\n   macro avg       0.54      0.54      0.53       199\nweighted avg       0.55      0.53      0.52       199\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":145}]}